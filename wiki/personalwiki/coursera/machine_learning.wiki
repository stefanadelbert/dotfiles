%title Machine Learning
%template default

*Machine Learning*

%toc

----

=  Introduction (Week 1) =
==  Welcome (7 min) ==
[Stanford autonomous helicopter](http://heli.stanford.edu/)
:: control software developed using machine learning techniques.
==  What is Machine Learning? (7 min) ==
*Arthur Samuel* (1959) - ability to learn without explicit programming. Good boards and bad boards learnt by the computer. Computer has patience. Got a lot of experience.

*Tom Mitchell* (1998) - computer programs learns if the _measurement_ (P) of the _performance_ (E) of a particular _task_ (T) improves.
 
 E
 :: `Experience`, e.g. playing a games of checkers, observing user clicking _Spam_
 
 T
 :: The `task` to be performed, e.g. to win a game of checkers, correctly classifying a spam email
 
 P
 :: The `probability` of successfully completing the task

Some forms of machine learning:

*Supervised learning*:: teach the computer, provide it the correct outcomes

*Unsupervised learning*:: computer learns by itself

*Reinforcement learning*:: _definition to come_

*Recommender systems*:: _definition to come_

==  Supervised Learning (12 min) ==

=== Regression Problem ===
*Predict a continuous valued output*, e.g. number of units sold, price of a house.

    Predicting housing prices when there is data as price ($) for a given size (floor area).
A learning algorithm would possibly be able to draw a _straight line_ through the data.
But another approach would be a _polynomial_, which would give a different predicted prices.
It's not obvious which one to choose.

_Supervised Learning_ means that the program is given the right answers. The program should then aim to provide more right answers.

=== Classification Problem ===
*Predict a discrete valued output*, e.g. malignant or benign tumour. There could be more than two possible outcomes, but they need to be discrete. 

Possible discrete outcomes could be denoted with _different symbols_.

There could be an infinite number of _features_ involved in a classification.

Support Vector Machine
:: neat trick which allows for dealing with an infinite number of features
==  Unsupervised Learning (14 min) ==
There is no indication of whether data is good or not or how it should be classified.
Need to find some structure in the data.

Clustering algorithm
:: clusters the data
:: An example would be grouping news stories that are similar
:: Another example is grouping people based on the occurrence of a gene in their DNA
:: Other examples:
 - Organising computing clusters
 - social network analysis
 - market segmentation
 - astronimical data analysis

    *Cocktail Party Problem*
    overlapping voices, hard to hear
    Two people, two microphones. Mics record different signals, but the signals do overlap. Algorithm can distinguish the two independent signals using one line of code.

Going to use _Octave_ in this course. It's a high level tool and that means that it's quicker to make progress and learn as a result. It's good for prototyping.

=  Linear Regression with One Variable (Week 1) =
==  Model Representation (8 min) ==

Univariate linear regression:: A regression with a single variable

Training set:: the data used to train a machine learning algorithm

Feature:: a stream or type of input data

Hypothesis:: the function which is the output of the learning algorithm

A Univariate linear regression hypothesis has the form:

{{$
h_\theta(x) = \theta_0 + \theta_1x
}}$

$h_\theta(x)$ can also be written as $h(x)$.

If the training set has 4 data points, then $m=4$. The inputs are $x$ and the outputs are $y$. The first input is $x^{(1)}$ and the corresponding output is $y^{(1)}$.

For example, given the training set
| row | input ($x$) | output ($y$) |
|-----|-------------|--------------|
| 1   | 100         | 1000         |
| 2   | 200         | 2000         |
| 3   | 300         | 3000         |
| 4   | 400         | 4000         |
then
{{$
\begin{align}
x^{(2)} &= 200 \\
y^{(2)} &= 2000
\end{align}
}}$

==  Cost Function (8 min) ==

Training Set
| row | input ($x$) | output ($y$) |
|-----|-------------|--------------|
| 1   | 2104        | 460          |
| 2   | 1461        | 232          |
| 3   | 1534        | 315          |
| 4   | 852         | 178          |

Hypothesis is in the form:
{{$
h_\theta(x) = \theta_0 + \theta_1x
}}$

The symbols, $\theta_0$ and $\theta_1$ are referred to as the _paramters_ of the model.

Come up with values for the parameters such that the straight line best approximates the training set. _How do we come up with the best parameters?_ 

We need to solve a _minimisation problem_ (sum of square errors).

{{$
\underset{\theta_0\theta_1}{minimise}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
}}$
This is known as the _objective function_ or _cost function_.
    <i class="icon-attention-circled"></i>Taking half the sum makes some of the maths easier down the track (apparently).

In the above
{{$
h_\theta(x^{(i)}) = \theta_0 + \theta_1x^{(i)}
}}$

_Cost function_ (_square error function_, _square error cost function_) is usualy defined as

{{$
J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
\underset{\theta_0\theta_1}{minimise}\,J(\theta_0, \theta_1)
}}$

Square error function is the most common cost function for linear regression problems. 
==  Cost Function - Intuition I (11 min) ==
    As a recap...
    
Hypothesis :: $ h_\theta(x) = \theta_0 + \theta_1x $

Parameters :: $ \theta_0,\theta_1 $

Cost Function :: $ J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 $

Goal :: $ \underset{\theta_0,\theta_1}{minimise}\,J(\theta_0,\theta_1) $

To better understand the cost function, it's useful to _simplify the hypothesis_ by assuming $\theta_0 = 0$, i.e.
{{$
h_\theta(x) = \theta_1x
}}$
The _cost function_ simplifies to:
{{$%align%
J(\theta_1) &= \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
{} &= \frac{1}{2m}\sum_{i=1}^m(\theta_1x^{(i)} - y^{(i)})^2
}}$

As different values for $\theta_1$ are chosen, the cost function yields different values. It's possible to plot the cost function, $J(\theta_1)$, and observe the minimum value.

If the chosen value of $\theta_1$ means that all points in the training set are perfectly satisfied by it, i.e. $\theta_1x^{(i)} = y^{(i)}$ for $i = 1..m$ then $J(\theta_1) = 0$ and the goal is met.
{{https://lh4.googleusercontent.com/-JYPxirkjACA/VL4ymKCdBAI/AAAAAAAAIag/Uv0HOZy3HUk/s0/Cost+Function+-+Intuition+I+%252811+min%2529+2015-01-20+21-39-55.png|Cost Function - Intuition I}}

    Note: There are some graphs and diagrams in the video which are fairly useful in explanation.
==  Cost Function - Intuition II (9 min) ==
Cost function for two variable looks like a surface. Can be visualized as a 3D plot.

Contour plot:: Another useful way to represent 3D surface.

==  Gradient Descent (11 min) ==
Gradient descent (repeat until convergence)::
$ \theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,...,\theta_n) $ for $ j = 0...n $

| $\alpha$ | learning rate |
| $\frac{\partial}{\partial\theta_j}$ | partial deivative|

    $:=$ should be distinguished from $=$. The former means assignment and the latter is a statement of equivalence. These correspond with `=` and `==` in C++.

When performing a gradient descent it's important to compute the new values for $\theta_0$ and $\theta_1$ _simultaneously_, i.e. using the same value of the cost function, $J(\theta_0, \theta_1)$.

==  Gradient Descent Intuition (12 min) ==
To understand what gradient descent is going to do, consider a single variable hypothesis with cost function, $J(\theta_1)$. Goal would be to minimise that.

Gradient descent would be for a single variable, $\theta_1$, and would look like this:
$ \theta_1 := \theta_1 - \alpha\frac{d}{d\theta_1}J(\theta_1) $.
Continue running this as long as the new value of $ \theta_1 $ reduces.

$\alpha$ (learning rate)
:: If it's _too small_ then the gradient descent can be _slow_
:: If it's _too large_ than the minimum can be _overshot_ or _fail to converge_ or even _diverge_

If the _starting point_ is already a _local optimum_ or _local minimum_ then the gradient will be zero and the new value of cost function would remain unchanged.

As the _local optimum_ is approached, that point will be approached more slowly as the _gradient reduces_. There is therefore _no need to change the value of_ $ \alpha $ over time.

==  Gradient Descent For Linear Regression (10 min) ==
Gradient Descent Algorithm::
{{$%align%
&\text{repeat until convergence} \{\\
&\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\ \text{for j = 0 and j = 1}\\
&\}
}}$

Linear Regression Model::
{{$%align%
h_\theta(x) &= \theta_0 + \theta_1x\\
J(\theta_0, \theta_1) &= \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2
}}$

Apply gradient descent in order to meet our goal. The key is working of the partial derivative term.

{{$%align%
\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) &= \frac{\partial}{\partial\theta_j}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\&= \frac{\partial}{\partial\theta_j}\frac{1}{2m}\sum_{i=1}^m(\theta_0 + \theta_1x^{(i)} - y^{(i)})^2
}}$

From this we need to get the functions used to calculate new values of $\theta_j$.

{{$%align%
&\theta_0\ (j = 0): \frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})\\
&\theta_1\ (j = 1): \frac{\partial}{\partial\theta_1} = J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)}).x^{(i)}
}}$

This yields the _gradient descent algorithm_
{{$%align%
&\text{repeat until convergence}\ \{\\
&\theta_0:=\theta_0 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})\\
&\theta_1:=\theta_1 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)}).x^{(i)}\\
&\}
}}$
    <i class="icon-attention"></i>$\theta_0$ and $\theta_1$ should be updated _simultaneously_.

The _cost function_ for a linear regression will always be a _bowl-shaped function_ or _convex function_.

*Batch gradient descent*
:: Gradient descent that considers every point in the training set for each step of the gradient descent.

*Normal equations method*
:: A technique for solving for the minimum directly rather than iteratively. Generally taught in advanced linear algebra courses.
:: The iterative approach _scales better_ though.

==  What's Next (6 min)  ==

=  Linear Algebra Review (Week 1, Optional) =
I've skipped this in the hope that the stuff will come back to me along the way.
==  Matrices and Vectors (9 min) ==
==  Addition and Scalar Multiplication (7 min) ==
==  Matrix Vector Multiplication (14 min) ==
==  Matrix Matrix Multiplication (11 min) ==
==  Matrix Multiplication Properties (9 min) ==
Matrix multiplcation is not commutative, i.e.
$A x B \neq B x A$
==  Inverse and Transpose (11 min)  ==

=  Linear Regression with Multiple Variables (Week 2) =

==  Multiple Features (8 min) ==
Using the original example, instead of just size, use some more input variable.

|Size ($x_1$)|Number of bedrooms ($x_2$)|Number of floors ($x_3$)|Age of home ($x_4$)|Price ($x_5$)|
|-|-|-|-|-|
|2104|5|1|45|460|
|1416|3|2|30|232|
|1534|3|2|30|315|
|852|2|1|36|178|
|...|...|...|...|...|

_Notation_
$m$
: The number of elements (training examples) in the _training set_
Number of rows in the table

$n$
: number of features
: 4 in this example

$x^{(i)}$
: input (features) of $i^{th}$ training example
: e.g. for $m=2$ $$x^{(2)} = \begin{bmatrix}1416\\3\\2\\40\end{bmatrix}$$

$x_j^{(i)}$
: value of the feature $j$ in the $i^{th}$ training example
: e.g. $x_3^{(2)} = 2$

Hypothesis has been
{{$
h_\theta(x) = \theta_0 + \theta_1x
}}$
 but will now become
{{$
h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n
}}$
For convenience, $x_0 = 1$

{{$
x=\begin{bmatrix}x_0\\x_1\\\vdots\\x_n\end{bmatrix}\in\mathbb{R}^{n+1}\\\theta=\begin{bmatrix}\theta_0\\\theta_1\\\vdots\\\theta_n\end{bmatrix} \in \mathbb{R}^{n+1}
}}$

{{$
\begin{align}
h_\theta(x) &= \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\\
&=\theta^Tx\\
&=\begin{bmatrix}x_0 & x_1 & \cdots  & x_n\end{bmatrix}\begin{bmatrix}\theta_0 \\ \theta_1 \\ \vdots \\ \theta_n\end{bmatrix}
\end{align}
}}$

This is the _inner product_ of the _parameter vector_ and _feature vector_, which is a convenient way to write the hypothesis. This is known as _Multivariate Linear Regression_ where _multivariate_ refers to there being multiple features.

==  Gradient Descent for Multiple Variables (5 min) ==
How to use gradient descent for multiple features.

Hypothesis
: {{$
h_\theta(x) =\theta^Tx = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\\
}}$

Parameters
: $\theta_0,\theta_1,\cdots,\theta_n\rightarrow\theta\,\text{[n+1 dimensional vector]}$

Cost Function
: {{$
\begin{align}
J(\theta_0,\theta_1,\cdots,\theta_n)&\rightarrow J(\theta)\\&= \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2
\end{align}
}}$

Gradient descent
: {{$
\begin{align}
&\text{Repeat }\{\\
&\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,\cdots,\theta_n)\\&\}
\end{align}
}}$

Some simplifications
{{$
\begin{align}
J(\theta_0,\theta_1,\cdots,\theta_n) &\rightarrow J(\theta)\\
\frac{\partial}{\partial\theta_j}J(\theta)
 &\rightarrow \sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_j^{(i)}
\end{align}
}}$

So, for $n\geq1$, the gradient descent could be written as
{{$
\begin{align}
&\text{Repeat}\ \{\\
&\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_j^{(i)}\\
&\}\ \text{(simultaneously update}\ \theta_j\  \text{for}\ j = 0,\cdots,n\text{)}\\
\end{align}
}}$

Go with the convention that $x_0^{(i)} = 1$.

{{$
\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_0^{(i)}\\
\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_1^{(i)}\\
\theta_2 := \theta_2 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_2^{(i)}\\
\vdots
}}$

==  Gradient Descent in Practice I - Feature Scaling (9 min) ==
Try to normalise the feature values, i.e. get them into the same range of values. This can be visualised using the contour plot

Scaling
: If the values are in _different ranges_, then the contour plot is more like a set of very _oblong ellipses_
: If there are in the _same range_, then the contour plot is more like a set on _concentric circles_ and gradient descent will have an easier time homing in on the minimum vale.
Get them in the same range by _scaling_ the values, such that the feature values are in the range $0 \leq x_i \leq 1$. If that is not exactly the case, it doesn't matter. Same order of magnitude is OK.
Aim for ranges like:
: {{$-3 \leq x_i \leq 3\\
-\frac{1}{3} \leq x_i \leq \frac{1}{3}}}$
 
Mean Normalisation
: An alternative to the scaling approach above
: Replace $x_i$ with $x_i = \mu_i$ to give feature values a mean of approximately zero.
: No need to do this for $x_0 = 1$, e.g. {{$
\begin{align}
&x_1 = \frac{size - 1000}{2000}\\
&x_2 = \frac{\#bedrooms-2}{5}\\
&-0.5 \leq x_1 \leq 0.5, -0.5 \leq x_2 \leq 0.5
\end{align}
}}$
For each feature value $x_1^{(i)}$, perform the transform
{{$
\begin{align}
&&x_1^{(i)} := \frac{x_1^{(i)} - \mu_1}{s_1}\\
&\text{where}&\\
&&\mu_1 \text{ is the mean of }x_1\\
&&s_1 \text{ is the range of }x_1
\end{align}
}}$

==  Gradient Descent in Practice II - Learning Rate (9 min) ==
Practical rules for determining the _learning rate_, $\alpha$.

To check that gradient descent is working properly, plot $J(\theta)$ against number of iterations as gradient descent runs. Should give a descending plot. $J(\theta)$ should decrease after every iteration.

if $J(\theta)$ increases with number of iterations, that's usually a suggestion that $\alpha$ is _too large_.

    If $\alpha$ is _too large_ then gradient can _overshoot_, for example if $J(\theta)$ is parabolic.

If $J(\theta)$ bounces, it can also suggest that $\alpha$ is too large.

    If $\alpha$ is _too small_, then gradient descent can be _too slow_.

When choosing $\alpha$, try
$ \cdots, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, \cdots $

Go with the value that seems to cause $J(\theta)$ to reduce quickly and with every iteration.

<i class="icon-comment"></i> There is a mathematical proof proving that gradient descent _will decrease with every iteration_ provided that $\alpha$ is chosen correctly.

==  Features and Polynomial Regression (8 min) ==

- Choice of features
- Polynomial regression

_Choice of Features_
You can create new features from the existing ones. Existing features could be combined.

For example, if the sample data has width and depth of the property, rather than using both those features, instead combine them as area.

_Polynomial Regression_

Could choose hypothesis to be second or third order:

{{$
\begin{align}
&\theta_0 + \theta_1x + \theta_2x^2\\
&\theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3
\end{align}
}}$

This form of hypothesis could be used with the the machinery of multi-variate linear regression, like this:

{{$
\begin{align}
h_\theta(x) &= \theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3\\
&=\theta_0 + \theta_1(size) + \theta_2(size)^2 + \theta_3(size)^3\\
x_1 &= (size)\\
x_2 &= (size)^2\\
x_3 &= (size)^3\\
\end{align}
}}$

<i class="icon-attention"></i>_Feature scaling_ is very important to get $x_1, x_2, x_3$ in the same range.

_Other Forms of Hypothesis_
Instead of a higher order term, consider using something else which might give a better fit, e.g. instead of the top hypothesis, use the bottom one
{{$
\begin{align}
h_\theta(x) &= \theta_0 + \theta_1x + \theta_2x^2\\
\rightarrow h_\theta(x) &= \theta_0 + \theta_1x + \theta_2\sqrt{(size)}
\end{align}
}}$

There is an algorithm which can be used to choose which form of hypothesis would best suit the data.

==  Normal Equation (16 min) ==
Normal equation allows for solving for $J(\theta)$ analytically.
There are advantages and disadvantages.

Simplified case where cost function is quadratic:
{{$
J(\theta) = a\theta^2 + b\theta + c
}}$

To find minimum of a quadratic, take the derivative and set it to zero and solve. Same idea can be used by setting the partial derivatives of the cost funtion for each $\theta_0,\theta_1,\cdots,\theta_n$ to zero and then solving, i.e.

{{$
\begin{align}
&\frac{\partial}{\partial\theta_j}J(\theta)=\cdots=0\ \text{(for every } j \text{)}\\
&\text{Solve for } \theta_0,\theta_1,\cdots,\theta_n
\end{align}
}}$

In the example, there are four feaures and $m=4$

- add a feature $x_0$ with values 1.
- put all features into a vector, $X$
- put all outcomes into a vector, $y$

{{$
X = \begin{bmatrix}
1 &2104 &5 &1 &45\\
1 &1416 &3 &2 &40\\
1 &1534 &3 &2 &30\\
1 &852 &2 &1 &36
\end{bmatrix}
y = \begin{bmatrix}
460\\
232\\
315\\
178
\end{bmatrix}
}}$

{{$
\theta = (X^TX)^{-1}X^Ty
}}$

_Design Matrix_
Features look like
{{$
x^{(i)} = \begin{bmatrix}
x_0^{(i)}\\
x_1^{(i)}\\
x_2^{(i)}\\
\vdots\\
x_n^{(i)}\\
\end{bmatrix}
}}$
To construct the _design matrix_, take the transpose of each $x^{(i)}$ as each elements of $X$.

{{$
X = \begin{bmatrix}
(x^{(1)})^T\\
(x^{(2)})^T\\
\vdots\\
(x^{(m)})^T
\end{bmatrix}
}}$

The just compute for $\theta$ using
{{$
\theta = (X^TX)^{-1}X^Ty
}}$

use `pinv()` in _Octave_ to calculate the inverse.

Calculating a matrix inverse can be expensive, typically $O(n^3)$. Use the normal equation unless the number of features is greater than $10000$.

Normal equation doesn't work for some of the more complicate machine learning approaches.
==  Normal Equation Noninvertibility (Optional) (6 min)  ==
Octave has `pinv` (_pseudo inverse_) and `inv`.

If $X^TX$ is non-invertible, the the normal equation is not going to work.

Things that can make $X^TX$ non-invertible:

- Redundant features
if two features are linearly related, then $X^TX$ will be non-invertible
- Too many features, $m \leq n$
Remove some features to make this work or use _regularization_.

If $X^TX$ is singular or non-invertible get rid of features where possible or use regularization.

=  Octave Tutorial (Week 2) =
==  Basic Operations (14 min) ==
==  Moving Data Around (16 min) ==
==  Computing on Data (13 min) ==
==  Plotting Data (10 min) ==
==  Control Statements: for, while, if statements (13 min) ==
==  Vectorization (14 min) ==
==  Working on and Submitting Programming Exercises (4 min)  ==
=  Logistic Regression (Week 3) =
==  Classification (8 min) ==
==  Hypothesis Representation (7 min) ==
==  Decision Boundary (15 min) ==
==  Cost Function (11 min) ==
==  Simplified Cost Function and Gradient Descent (10 min) ==
==  Advanced Optimization (14 min) ==
==  Multiclass Classification: One-vs-all (6 min)  ==
=  Regularization (Week 3) =
==  The Problem of Overfitting (10 min) ==
==  Cost Function (10 min) ==
==  Regularized Linear Regression (11 min) ==
==  Regularized Logistic Regression (9 min)  ==
=  Neural Networks: Representation (Week 4) =
==  Non-linear Hypotheses (10 min) ==
==  Neurons and the Brain (8 min) ==
==  Model Representation I (12 min) ==
==  Model Representation II (12 min) ==
==  Examples and Intuitions I (7 min) ==
==  Examples and Intuitions II (10 min) ==
==  Multiclass Classification (4 min)  ==
=  Neural Networks: Learning (Week 5) =
==  Cost Function (7 min) ==
==  Backpropagation Algorithm (12 min) ==
==  Backpropagation Intuition (13 min) ==
==  Implementation Note: Unrolling Parameters (8 min) ==
==  Gradient Checking (12 min) ==
==  Random Initialization (7 min) ==
==  Putting It Together (14 min) ==
==  Autonomous Driving (7 min)  ==
=  Advice for Applying Machine Learning (Week 6) =
==  Deciding What to Try Next (6 min) ==
==  Evaluating a Hypothesis (8 min) ==
==  Model Selection and Train/Validation/Test Sets (12 min) ==
==  Diagnosing Bias vs# Variance (8 min) ==
==  Regularization and Bias/Variance (11 min) ==
==  Learning Curves (12 min) ==
==  Deciding What to Do Next Revisited (7 min)  ==
=  Machine Learning System Design (Week 6) =
==  Prioritizing What to Work On (10 min) ==
==  Error Analysis (13 min) ==
==  Error Metrics for Skewed Classes (12 min) ==
==  Trading Off Precision and Recall (14 min) ==
==  Data For Machine Learning (11 min)  ==
=  Support Vector Machines (Week 7) =
==  Optimization Objective (15 min) ==
==  Large Margin Intuition (11 min) ==
==  Mathematics Behind Large Margin Classification (Optional) (20 min) ==
==  Kernels I (16 min) ==
==  Kernels II (16 min) ==
==  Using An SVM (21 min)  ==
=  Clustering (Week 8) =
==  Unsupervised Learning: Introduction (3 min) ==
==  K-Means Algorithm (13 min) ==
==  Optimization Objective (7 min) ==
==  Random Initialization (8 min) ==
==  Choosing the Number of Clusters (8 min)  ==
=  Dimensionality Reduction (Week 8) =
==  Motivation I: Data Compression (10 min) ==
==  Motivation II: Visualization (6 min) ==
==  Principal Component Analysis Problem Formulation (9 min) ==
==  Principal Component Analysis Algorithm (15 min) ==
==  Choosing the Number of Principal Components (11 min) ==
==  Reconstruction from Compressed Representation (4 min) ==
==  Advice for Applying PCA (13 min)  ==
=  Anomaly Detection (Week 9) =
==  Problem Motivation (8 min) ==
==  Gaussian Distribution (10 min) ==
==  Algorithm (12 min) ==
==  Developing and Evaluating an Anomaly Detection System (13 min) ==
==  Anomaly Detection vs# Supervised Learning (8 min) ==
==  Choosing What Features to Use (12 min) ==
==  Multivariate Gaussian Distribution (Optional) (14 min) ==
==  Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min)  ==
=  Recommender Systems (Week 9) =
==  Problem Formulation (8 min) ==
==  Content Based Recommendations (15 min) ==
==  Collaborative Filtering (10 min) ==
==  Collaborative Filtering Algorithm (9 min) ==
==  Vectorization: Low Rank Matrix Factorization (8 min) ==
==  Implementational Detail: Mean Normalization (9 min)  ==
=  Large Scale Machine Learning (Week 10) =
==  Learning With Large Datasets (6 min) ==
==  Stochastic Gradient Descent (13 min) ==
==  Mini-Batch Gradient Descent (6 min) ==
==  Stochastic Gradient Descent Convergence (12 min) ==
==  Online Learning (13 min) ==
==  Map Reduce and Data Parallelism (14 min)  ==
=  Application Example: Photo OCR =
==  Problem Description and Pipeline (7 min) ==
==  Sliding Windows (15 min) ==
==  Getting Lots of Data and Artificial Data (16 min) ==
==  Ceiling Analysis: What Part of the Pipeline to Work on Next (14 min)  ==
=  Conclusion =
==  Summary and Thank You (5 min) ==
