<html>
<head>
    <link rel="Stylesheet" type="text/css" href="../style.css" />
    <title>Machine Learning</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</head>
<body>
    <a href="../index.html">Index</a> |
    <a href="../diary/diary.html">Diary</a>
    <hr>
    <div class="content">
    

<p>
<strong>Machine Learning</strong>
</p>

<div class="toc">
<ul>
<li><a href="#toc_1">Introduction (Week 1)</a>
<ul>
<li><a href="#toc_1.1">Welcome (7 min)</a>
<li><a href="#toc_1.2">What is Machine Learning? (7 min)</a>
<li><a href="#toc_1.3">Supervised Learning (12 min)</a>
<ul>
<li><a href="#toc_1.3.1">Regression Problem</a>
<li><a href="#toc_1.3.2">Classification Problem</a>
</ul>
<li><a href="#toc_1.4">Unsupervised Learning (14 min)</a>
</ul>
<li><a href="#toc_2">Linear Regression with One Variable (Week 1)</a>
<ul>
<li><a href="#toc_2.1">Model Representation (8 min)</a>
<li><a href="#toc_2.2">Cost Function (8 min)</a>
<li><a href="#toc_2.3">Cost Function - Intuition I (11 min)</a>
<li><a href="#toc_2.4">Cost Function - Intuition II (9 min)</a>
<li><a href="#toc_2.5">Gradient Descent (11 min)</a>
<li><a href="#toc_2.6">Gradient Descent Intuition (12 min)</a>
<li><a href="#toc_2.7">Gradient Descent For Linear Regression (10 min)</a>
<li><a href="#toc_2.8">What's Next (6 min)</a>
</ul>
<li><a href="#toc_3">Linear Algebra Review (Week 1, Optional)</a>
<ul>
<li><a href="#toc_3.1">Matrices and Vectors (9 min)</a>
<li><a href="#toc_3.2">Addition and Scalar Multiplication (7 min)</a>
<li><a href="#toc_3.3">Matrix Vector Multiplication (14 min)</a>
<li><a href="#toc_3.4">Matrix Matrix Multiplication (11 min)</a>
<li><a href="#toc_3.5">Matrix Multiplication Properties (9 min)</a>
<li><a href="#toc_3.6">Inverse and Transpose (11 min)</a>
</ul>
<li><a href="#toc_4">Linear Regression with Multiple Variables (Week 2)</a>
<ul>
<li><a href="#toc_4.1">Multiple Features (8 min)</a>
<li><a href="#toc_4.2">Gradient Descent for Multiple Variables (5 min)</a>
<li><a href="#toc_4.3">Gradient Descent in Practice I - Feature Scaling (9 min)</a>
<li><a href="#toc_4.4">Gradient Descent in Practice II - Learning Rate (9 min)</a>
<li><a href="#toc_4.5">Features and Polynomial Regression (8 min)</a>
<li><a href="#toc_4.6">Normal Equation (16 min)</a>
<li><a href="#toc_4.7">Normal Equation Noninvertibility (Optional) (6 min)</a>
</ul>
<li><a href="#toc_5">Octave Tutorial (Week 2)</a>
<ul>
<li><a href="#toc_5.1">Basic Operations (14 min)</a>
<li><a href="#toc_5.2">Moving Data Around (16 min)</a>
<li><a href="#toc_5.3">Computing on Data (13 min)</a>
<li><a href="#toc_5.4">Plotting Data (10 min)</a>
<li><a href="#toc_5.5">Control Statements: for, while, if statements (13 min)</a>
<li><a href="#toc_5.6">Vectorization (14 min)</a>
<li><a href="#toc_5.7">Working on and Submitting Programming Exercises (4 min)</a>
</ul>
<li><a href="#toc_6">Logistic Regression (Week 3)</a>
<ul>
<li><a href="#toc_6.1">Classification (8 min)</a>
<li><a href="#toc_6.2">Hypothesis Representation (7 min)</a>
<li><a href="#toc_6.3">Decision Boundary (15 min)</a>
<li><a href="#toc_6.4">Cost Function (11 min)</a>
<li><a href="#toc_6.5">Simplified Cost Function and Gradient Descent (10 min)</a>
<li><a href="#toc_6.6">Advanced Optimization (14 min)</a>
<li><a href="#toc_6.7">Multiclass Classification: One-vs-all (6 min)</a>
</ul>
<li><a href="#toc_7">Regularization (Week 3)</a>
<ul>
<li><a href="#toc_7.1">The Problem of Overfitting (10 min)</a>
<li><a href="#toc_7.2">Cost Function (10 min)</a>
<li><a href="#toc_7.3">Regularized Linear Regression (11 min)</a>
<li><a href="#toc_7.4">Regularized Logistic Regression (9 min)</a>
</ul>
<li><a href="#toc_8">Neural Networks: Representation (Week 4)</a>
<ul>
<li><a href="#toc_8.1">Non-linear Hypotheses (10 min)</a>
<li><a href="#toc_8.2">Neurons and the Brain (8 min)</a>
<li><a href="#toc_8.3">Model Representation I (12 min)</a>
<li><a href="#toc_8.4">Model Representation II (12 min)</a>
<li><a href="#toc_8.5">Examples and Intuitions I (7 min)</a>
<li><a href="#toc_8.6">Examples and Intuitions II (10 min)</a>
<li><a href="#toc_8.7">Multiclass Classification (4 min)</a>
</ul>
<li><a href="#toc_9">Neural Networks: Learning (Week 5)</a>
<ul>
<li><a href="#toc_9.1">Cost Function (7 min)</a>
<li><a href="#toc_9.2">Backpropagation Algorithm (12 min)</a>
<li><a href="#toc_9.3">Backpropagation Intuition (13 min)</a>
<li><a href="#toc_9.4">Implementation Note: Unrolling Parameters (8 min)</a>
<li><a href="#toc_9.5">Gradient Checking (12 min)</a>
<li><a href="#toc_9.6">Random Initialization (7 min)</a>
<li><a href="#toc_9.7">Putting It Together (14 min)</a>
<li><a href="#toc_9.8">Autonomous Driving (7 min)</a>
</ul>
<li><a href="#toc_10">Advice for Applying Machine Learning (Week 6)</a>
<ul>
<li><a href="#toc_10.1">Deciding What to Try Next (6 min)</a>
<li><a href="#toc_10.2">Evaluating a Hypothesis (8 min)</a>
<li><a href="#toc_10.3">Model Selection and Train/Validation/Test Sets (12 min)</a>
<li><a href="#toc_10.4">Diagnosing Bias vs# Variance (8 min)</a>
<li><a href="#toc_10.5">Regularization and Bias/Variance (11 min)</a>
<li><a href="#toc_10.6">Learning Curves (12 min)</a>
<li><a href="#toc_10.7">Deciding What to Do Next Revisited (7 min)</a>
</ul>
<li><a href="#toc_11">Machine Learning System Design (Week 6)</a>
<ul>
<li><a href="#toc_11.1">Prioritizing What to Work On (10 min)</a>
<li><a href="#toc_11.2">Error Analysis (13 min)</a>
<li><a href="#toc_11.3">Error Metrics for Skewed Classes (12 min)</a>
<li><a href="#toc_11.4">Trading Off Precision and Recall (14 min)</a>
<li><a href="#toc_11.5">Data For Machine Learning (11 min)</a>
</ul>
<li><a href="#toc_12">Support Vector Machines (Week 7)</a>
<ul>
<li><a href="#toc_12.1">Optimization Objective (15 min)</a>
<li><a href="#toc_12.2">Large Margin Intuition (11 min)</a>
<li><a href="#toc_12.3">Mathematics Behind Large Margin Classification (Optional) (20 min)</a>
<li><a href="#toc_12.4">Kernels I (16 min)</a>
<li><a href="#toc_12.5">Kernels II (16 min)</a>
<li><a href="#toc_12.6">Using An SVM (21 min)</a>
</ul>
<li><a href="#toc_13">Clustering (Week 8)</a>
<ul>
<li><a href="#toc_13.1">Unsupervised Learning: Introduction (3 min)</a>
<li><a href="#toc_13.2">K-Means Algorithm (13 min)</a>
<li><a href="#toc_13.3">Optimization Objective (7 min)</a>
<li><a href="#toc_13.4">Random Initialization (8 min)</a>
<li><a href="#toc_13.5">Choosing the Number of Clusters (8 min)</a>
</ul>
<li><a href="#toc_14">Dimensionality Reduction (Week 8)</a>
<ul>
<li><a href="#toc_14.1">Motivation I: Data Compression (10 min)</a>
<li><a href="#toc_14.2">Motivation II: Visualization (6 min)</a>
<li><a href="#toc_14.3">Principal Component Analysis Problem Formulation (9 min)</a>
<li><a href="#toc_14.4">Principal Component Analysis Algorithm (15 min)</a>
<li><a href="#toc_14.5">Choosing the Number of Principal Components (11 min)</a>
<li><a href="#toc_14.6">Reconstruction from Compressed Representation (4 min)</a>
<li><a href="#toc_14.7">Advice for Applying PCA (13 min)</a>
</ul>
<li><a href="#toc_15">Anomaly Detection (Week 9)</a>
<ul>
<li><a href="#toc_15.1">Problem Motivation (8 min)</a>
<li><a href="#toc_15.2">Gaussian Distribution (10 min)</a>
<li><a href="#toc_15.3">Algorithm (12 min)</a>
<li><a href="#toc_15.4">Developing and Evaluating an Anomaly Detection System (13 min)</a>
<li><a href="#toc_15.5">Anomaly Detection vs# Supervised Learning (8 min)</a>
<li><a href="#toc_15.6">Choosing What Features to Use (12 min)</a>
<li><a href="#toc_15.7">Multivariate Gaussian Distribution (Optional) (14 min)</a>
<li><a href="#toc_15.8">Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min)</a>
</ul>
<li><a href="#toc_16">Recommender Systems (Week 9)</a>
<ul>
<li><a href="#toc_16.1">Problem Formulation (8 min)</a>
<li><a href="#toc_16.2">Content Based Recommendations (15 min)</a>
<li><a href="#toc_16.3">Collaborative Filtering (10 min)</a>
<li><a href="#toc_16.4">Collaborative Filtering Algorithm (9 min)</a>
<li><a href="#toc_16.5">Vectorization: Low Rank Matrix Factorization (8 min)</a>
<li><a href="#toc_16.6">Implementational Detail: Mean Normalization (9 min)</a>
</ul>
<li><a href="#toc_17">Large Scale Machine Learning (Week 10)</a>
<ul>
<li><a href="#toc_17.1">Learning With Large Datasets (6 min)</a>
<li><a href="#toc_17.2">Stochastic Gradient Descent (13 min)</a>
<li><a href="#toc_17.3">Mini-Batch Gradient Descent (6 min)</a>
<li><a href="#toc_17.4">Stochastic Gradient Descent Convergence (12 min)</a>
<li><a href="#toc_17.5">Online Learning (13 min)</a>
<li><a href="#toc_17.6">Map Reduce and Data Parallelism (14 min)</a>
</ul>
<li><a href="#toc_18">Application Example: Photo OCR</a>
<ul>
<li><a href="#toc_18.1">Problem Description and Pipeline (7 min)</a>
<li><a href="#toc_18.2">Sliding Windows (15 min)</a>
<li><a href="#toc_18.3">Getting Lots of Data and Artificial Data (16 min)</a>
<li><a href="#toc_18.4">Ceiling Analysis: What Part of the Pipeline to Work on Next (14 min)</a>
</ul>
<li><a href="#toc_19">Conclusion</a>
<ul>
<li><a href="#toc_19.1">Summary and Thank You (5 min)</a>
</ul>
</ul>
</div>

<hr />

<h1 id="toc_1">Introduction (Week 1)</h1>
<h2 id="toc_1.1">Welcome (7 min)</h2>
<p>
[Stanford autonomous helicopter](<a href="http://heli.stanford.edu/)">http://heli.stanford.edu/)</a>
<dl>
<dd>control software developed using machine learning techniques.</dd>
</p>
<h2 id="toc_1.2">What is Machine Learning? (7 min)</h2>
</dl>
<p>
<strong>Arthur Samuel</strong> (1959) - ability to learn without explicit programming. Good boards and bad boards learnt by the computer. Computer has patience. Got a lot of experience.
</p>

<p>
<strong>Tom Mitchell</strong> (1998) - computer programs learns if the <em>measurement</em> (P) of the <em>performance</em> (E) of a particular <em>task</em> (T) improves.
</p>
 
<p>
 E
<dl>
<dt> </dt>
<dd><code>Experience</code>, e.g. playing a games of checkers, observing user clicking <em>Spam</em></dd>
</dl>
</p>
 
<p>
 T
<dl>
<dt> </dt>
<dd>The <code>task</code> to be performed, e.g. to win a game of checkers, correctly classifying a spam email</dd>
</dl>
</p>
 
<p>
 P
<dl>
<dt> </dt>
<dd>The <code>probability</code> of successfully completing the task</dd>
</dl>
</p>

<p>
Some forms of machine learning:
</p>

<dl>
<dt><strong>Supervised learning</strong></dt>
<dd>teach the computer, provide it the correct outcomes</dd>
</dl>

<dl>
<dt><strong>Unsupervised learning</strong></dt>
<dd>computer learns by itself</dd>
</dl>

<dl>
<dt><strong>Reinforcement learning</strong></dt>
<dd><em>definition to come</em></dd>
</dl>

<dl>
<dt><strong>Recommender systems</strong></dt>
<dd><em>definition to come</em></dd>
</dl>

<h2 id="toc_1.3">Supervised Learning (12 min)</h2>

<h3 id="toc_1.3.1">Regression Problem</h3>
<p>
<strong>Predict a continuous valued output</strong>, e.g. number of units sold, price of a house.
</p>
<blockquote>
Predicting housing prices when there is data as price ($) for a given size (floor area).
</blockquote>
<p>
A learning algorithm would possibly be able to draw a <em>straight line</em> through the data.
But another approach would be a <em>polynomial</em>, which would give a different predicted prices.
It's not obvious which one to choose.
</p>

<p>
<em>Supervised Learning</em> means that the program is given the right answers. The program should then aim to provide more right answers.
</p>

<h3 id="toc_1.3.2">Classification Problem</h3>
<p>
<strong>Predict a discrete valued output</strong>, e.g. malignant or benign tumour. There could be more than two possible outcomes, but they need to be discrete. 
</p>

<p>
Possible discrete outcomes could be denoted with <em>different symbols</em>.
</p>

<p>
There could be an infinite number of <em>features</em> involved in a classification.
</p>

<p>
Support Vector Machine
<dl>
<dd>neat trick which allows for dealing with an infinite number of features</dd>
</p>
<h2 id="toc_1.4">Unsupervised Learning (14 min)</h2>
</dl>
<p>
There is no indication of whether data is good or not or how it should be classified.
Need to find some structure in the data.
</p>

<p>
Clustering algorithm
<dl>
<dd>clusters the data</dd>
<dd>An example would be grouping news stories that are similar</dd>
<dd>Another example is grouping people based on the occurrence of a gene in their DNA</dd>
<dd>Other examples:</dd>
</p>
</dl>
<ul>
<li>
Organising computing clusters

<li>
social network analysis

<li>
market segmentation

<li>
astronimical data analysis

</ul>
<blockquote>
<strong>Cocktail Party Problem</strong>
overlapping voices, hard to hear
Two people, two microphones. Mics record different signals, but the signals do overlap. Algorithm can distinguish the two independent signals using one line of code.
</blockquote>

<p>
Going to use <em>Octave</em> in this course. It's a high level tool and that means that it's quicker to make progress and learn as a result. It's good for prototyping.
</p>

<h1 id="toc_2">Linear Regression with One Variable (Week 1)</h1>
<h2 id="toc_2.1">Model Representation (8 min)</h2>

<dl>
<dt>Univariate linear regression</dt>
<dd>A regression with a single variable</dd>
</dl>

<dl>
<dt>Training set</dt>
<dd>the data used to train a machine learning algorithm</dd>
</dl>

<dl>
<dt>Feature</dt>
<dd>a stream or type of input data</dd>
</dl>

<dl>
<dt>Hypothesis</dt>
<dd>the function which is the output of the learning algorithm</dd>
</dl>

<p>
A Univariate linear regression hypothesis has the form:
</p>

\[
h_\theta(x) = \theta_0 + \theta_1x
\]

<p>
\(h_\theta(x)\) can also be written as \(h(x)\).
</p>

<p>
If the training set has 4 data points, then \(m=4\). The inputs are \(x\) and the outputs are \(y\). The first input is \(x^{(1)}\) and the corresponding output is \(y^{(1)}\).
</p>

<p>
For example, given the training set
<table>
<tr>
<th>
row
</th>
<th>
input (\(x\))
</th>
<th>
output (\(y\))
</th>
</tr>
<tr>
<td>
1
</td>
<td>
100
</td>
<td>
1000
</td>
</tr>
<tr>
<td>
2
</td>
<td>
200
</td>
<td>
2000
</td>
</tr>
<tr>
<td>
3
</td>
<td>
300
</td>
<td>
3000
</td>
</tr>
<tr>
<td>
4
</td>
<td>
400
</td>
<td>
4000
</td>
</tr>
</table>
then
</p>
\[
\begin{align}
x^{(2)} &amp;= 200 \\
y^{(2)} &amp;= 2000
\end{align}
\]

<h2 id="toc_2.2">Cost Function (8 min)</h2>

<p>
Training Set
<table>
<tr>
<th>
row
</th>
<th>
input (\(x\))
</th>
<th>
output (\(y\))
</th>
</tr>
<tr>
<td>
1
</td>
<td>
2104
</td>
<td>
460
</td>
</tr>
<tr>
<td>
2
</td>
<td>
1461
</td>
<td>
232
</td>
</tr>
<tr>
<td>
3
</td>
<td>
1534
</td>
<td>
315
</td>
</tr>
<tr>
<td>
4
</td>
<td>
852
</td>
<td>
178
</td>
</tr>
</table>
</p>

<p>
Hypothesis is in the form:
</p>
\[
h_\theta(x) = \theta_0 + \theta_1x
\]

<p>
The symbols, \(\theta_0\) and \(\theta_1\) are referred to as the <em>paramters</em> of the model.
</p>

<p>
Come up with values for the parameters such that the straight line best approximates the training set. <em>How do we come up with the best parameters?</em> 
</p>

<p>
We need to solve a <em>minimisation problem</em> (sum of square errors).
</p>

\[
\underset{\theta_0\theta_1}{minimise}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
\]
<p>
This is known as the <em>objective function</em> or <em>cost function</em>.
</p>
<blockquote>
<i class="icon-attention-circled"></i>Taking half the sum makes some of the maths easier down the track (apparently).
</blockquote>

<p>
In the above
</p>
\[
h_\theta(x^{(i)}) = \theta_0 + \theta_1x^{(i)}
\]

<p>
<em>Cost function</em> (<em>square error function</em>, <em>square error cost function</em>) is usualy defined as
</p>

\[
J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
\underset{\theta_0\theta_1}{minimise}\,J(\theta_0, \theta_1)
\]

<p>
Square error function is the most common cost function for linear regression problems. 
</p>
<h2 id="toc_2.3">Cost Function - Intuition I (11 min)</h2>
<blockquote>
As a recap...
</blockquote>
    
<dl>
<dt>Hypothesis </dt>
<dd>\( h_\theta(x) = \theta_0 + \theta_1x \)</dd>
</dl>

<dl>
<dt>Parameters </dt>
<dd>\( \theta_0,\theta_1 \)</dd>
</dl>

<dl>
<dt>Cost Function </dt>
<dd>\( J(\theta_0, \theta_1) = \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2 \)</dd>
</dl>

<dl>
<dt>Goal </dt>
<dd>\( \underset{\theta_0,\theta_1}{minimise}\,J(\theta_0,\theta_1) \)</dd>
</dl>

<p>
To better understand the cost function, it's useful to <em>simplify the hypothesis</em> by assuming \(\theta_0 = 0\), i.e.
</p>
\[
h_\theta(x) = \theta_1x
\]
<p>
The <em>cost function</em> simplifies to:
</p>
\begin{align}
J(\theta_1) &amp;= \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\
{} &amp;= \frac{1}{2m}\sum_{i=1}^m(\theta_1x^{(i)} - y^{(i)})^2
\end{align}

<p>
As different values for \(\theta_1\) are chosen, the cost function yields different values. It's possible to plot the cost function, \(J(\theta_1)\), and observe the minimum value.
</p>

<p>
If the chosen value of \(\theta_1\) means that all points in the training set are perfectly satisfied by it, i.e. \(\theta_1x^{(i)} = y^{(i)}\) for \(i = 1..m\) then \(J(\theta_1) = 0\) and the goal is met.
<img src="https://lh4.googleusercontent.com/-JYPxirkjACA/VL4ymKCdBAI/AAAAAAAAIag/Uv0HOZy3HUk/s0/Cost+Function+-+Intuition+I+%252811+min%2529+2015-01-20+21-39-55.png" alt="Cost Function - Intuition I" />
</p>
<blockquote>
Note: There are some graphs and diagrams in the video which are fairly useful in explanation.
</blockquote>
<h2 id="toc_2.4">Cost Function - Intuition II (9 min)</h2>
<p>
Cost function for two variable looks like a surface. Can be visualized as a 3D plot.
</p>

<dl>
<dt>Contour plot</dt>
<dd>Another useful way to represent 3D surface.</dd>
</dl>

<h2 id="toc_2.5">Gradient Descent (11 min)</h2>
<dl>
<dt>Gradient descent (repeat until convergence)</dt>
</dl>
<p>
\( \theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,...,\theta_n) \) for \( j = 0...n \)
</p>

<table>
<tr>
<td>
\(\alpha\)
</td>
<td>
learning rate
</td>
</tr>
<tr>
<td>
\(\frac{\partial}{\partial\theta_j}\)
</td>
<td>
partial deivative
</td>
</tr>
</table>
<blockquote>
\(:=\) should be distinguished from \(=\). The former means assignment and the latter is a statement of equivalence. These correspond with <code>=</code> and <code>==</code> in C++.
</blockquote>

<p>
When performing a gradient descent it's important to compute the new values for \(\theta_0\) and \(\theta_1\) <em>simultaneously</em>, i.e. using the same value of the cost function, \(J(\theta_0, \theta_1)\).
</p>

<h2 id="toc_2.6">Gradient Descent Intuition (12 min)</h2>
<p>
To understand what gradient descent is going to do, consider a single variable hypothesis with cost function, \(J(\theta_1)\). Goal would be to minimise that.
</p>

<p>
Gradient descent would be for a single variable, \(\theta_1\), and would look like this:
\( \theta_1 := \theta_1 - \alpha\frac{d}{d\theta_1}J(\theta_1) \).
Continue running this as long as the new value of \( \theta_1 \) reduces.
</p>

<p>
\(\alpha\) (learning rate)
<dl>
<dd>If it's <em>too small</em> then the gradient descent can be <em>slow</em></dd>
<dd>If it's <em>too large</em> than the minimum can be <em>overshot</em> or <em>fail to converge</em> or even <em>diverge</em></dd>
</dl>
</p>

<p>
If the <em>starting point</em> is already a <em>local optimum</em> or <em>local minimum</em> then the gradient will be zero and the new value of cost function would remain unchanged.
</p>

<p>
As the <em>local optimum</em> is approached, that point will be approached more slowly as the <em>gradient reduces</em>. There is therefore <em>no need to change the value of</em> \( \alpha \) over time.
</p>

<h2 id="toc_2.7">Gradient Descent For Linear Regression (10 min)</h2>
<dl>
<dt>Gradient Descent Algorithm</dt>
</dl>
\begin{align}
&amp;\text{repeat until convergence} \{\\
&amp;\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1)\ \text{for j = 0 and j = 1}\\
&amp;\}
\end{align}

<dl>
<dt>Linear Regression Model</dt>
</dl>
\begin{align}
h_\theta(x) &amp;= \theta_0 + \theta_1x\\
J(\theta_0, \theta_1) &amp;= \frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2
\end{align}

<p>
Apply gradient descent in order to meet our goal. The key is working of the partial derivative term.
</p>

\begin{align}
\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1) &amp;= \frac{\partial}{\partial\theta_j}\frac{1}{2m}\sum_{i=1}^m(h_\theta(x^{(i)}) - y^{(i)})^2\\&amp;= \frac{\partial}{\partial\theta_j}\frac{1}{2m}\sum_{i=1}^m(\theta_0 + \theta_1x^{(i)} - y^{(i)})^2
\end{align}

<p>
From this we need to get the functions used to calculate new values of \(\theta_j\).
</p>

\begin{align}
&amp;\theta_0\ (j = 0): \frac{\partial}{\partial\theta_0}J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})\\
&amp;\theta_1\ (j = 1): \frac{\partial}{\partial\theta_1} = J(\theta_0,\theta_1)=\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)}).x^{(i)}
\end{align}

<p>
This yields the <em>gradient descent algorithm</em>
</p>
\begin{align}
&amp;\text{repeat until convergence}\ \{\\
&amp;\theta_0:=\theta_0 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)})\\
&amp;\theta_1:=\theta_1 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)}) - y^{(i)}).x^{(i)}\\
&amp;\}
\end{align}
<blockquote>
<i class="icon-attention"></i>\(\theta_0\) and \(\theta_1\) should be updated <em>simultaneously</em>.
</blockquote>

<p>
The <em>cost function</em> for a linear regression will always be a <em>bowl-shaped function</em> or <em>convex function</em>.
</p>

<p>
<strong>Batch gradient descent</strong>
<dl>
<dd>Gradient descent that considers every point in the training set for each step of the gradient descent.</dd>
</dl>
</p>

<p>
<strong>Normal equations method</strong>
<dl>
<dd>A technique for solving for the minimum directly rather than iteratively. Generally taught in advanced linear algebra courses.</dd>
<dd>The iterative approach <em>scales better</em> though.</dd>
</dl>
</p>

<h2 id="toc_2.8">What's Next (6 min)</h2>

<h1 id="toc_3">Linear Algebra Review (Week 1, Optional)</h1>
<p>
I've skipped this in the hope that the stuff will come back to me along the way.
</p>
<h2 id="toc_3.1">Matrices and Vectors (9 min)</h2>
<h2 id="toc_3.2">Addition and Scalar Multiplication (7 min)</h2>
<h2 id="toc_3.3">Matrix Vector Multiplication (14 min)</h2>
<h2 id="toc_3.4">Matrix Matrix Multiplication (11 min)</h2>
<h2 id="toc_3.5">Matrix Multiplication Properties (9 min)</h2>
<p>
Matrix multiplcation is not commutative, i.e.
\(A x B \neq B x A\)
</p>
<h2 id="toc_3.6">Inverse and Transpose (11 min)</h2>

<h1 id="toc_4">Linear Regression with Multiple Variables (Week 2)</h1>

<h2 id="toc_4.1">Multiple Features (8 min)</h2>
<p>
Using the original example, instead of just size, use some more input variable.
</p>

<table>
<tr>
<td>
Size (\(x_1\))
</td>
<td>
Number of bedrooms (\(x_2\))
</td>
<td>
Number of floors (\(x_3\))
</td>
<td>
Age of home (\(x_4\))
</td>
<td>
Price (\(x_5\))
</td>
</tr>
<tr>
<td>
-
</td>
<td>
-
</td>
<td>
-
</td>
<td>
-
</td>
<td>
-
</td>
</tr>
<tr>
<td>
2104
</td>
<td>
5
</td>
<td>
1
</td>
<td>
45
</td>
<td>
460
</td>
</tr>
<tr>
<td>
1416
</td>
<td>
3
</td>
<td>
2
</td>
<td>
30
</td>
<td>
232
</td>
</tr>
<tr>
<td>
1534
</td>
<td>
3
</td>
<td>
2
</td>
<td>
30
</td>
<td>
315
</td>
</tr>
<tr>
<td>
852
</td>
<td>
2
</td>
<td>
1
</td>
<td>
36
</td>
<td>
178
</td>
</tr>
<tr>
<td>
...
</td>
<td>
...
</td>
<td>
...
</td>
<td>
...
</td>
<td>
...
</td>
</tr>
</table>

<p>
<em>Notation</em>
\(m\)
: The number of elements (training examples) in the <em>training set</em>
Number of rows in the table
</p>

<p>
\(n\)
: number of features
: 4 in this example
</p>

<p>
\(x^{(i)}\)
: input (features) of \(i^{th}\) training example
: e.g. for \(m=2\) $\(x^{(2)} = \begin{bmatrix}1416\\3\\2\\40\end{bmatrix}\)$
</p>

<p>
\(x_j^{(i)}\)
: value of the feature \(j\) in the \(i^{th}\) training example
: e.g. \(x_3^{(2)} = 2\)
</p>

<p>
Hypothesis has been
</p>
\[
h_\theta(x) = \theta_0 + \theta_1x
\]
<p>
 but will now become
</p>
\[
h_\theta(x) = \theta_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n
\]
<p>
For convenience, \(x_0 = 1\)
</p>

\[
x=\begin{bmatrix}x_0\\x_1\\\vdots\\x_n\end{bmatrix}\in\mathbb{R}^{n+1}\\\theta=\begin{bmatrix}\theta_0\\\theta_1\\\vdots\\\theta_n\end{bmatrix} \in \mathbb{R}^{n+1}
\]

\[
\begin{align}
h_\theta(x) &amp;= \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\\
&amp;=\theta^Tx\\
&amp;=\begin{bmatrix}x_0 &amp; x_1 &amp; \cdots  &amp; x_n\end{bmatrix}\begin{bmatrix}\theta_0 \\ \theta_1 \\ \vdots \\ \theta_n\end{bmatrix}
\end{align}
\]

<p>
This is the <em>inner product</em> of the <em>parameter vector</em> and <em>feature vector</em>, which is a convenient way to write the hypothesis. This is known as <em>Multivariate Linear Regression</em> where <em>multivariate</em> refers to there being multiple features.
</p>

<h2 id="toc_4.2">Gradient Descent for Multiple Variables (5 min)</h2>
<p>
How to use gradient descent for multiple features.
</p>

<p>
Hypothesis
: {{$
h_\theta(x) =\theta^Tx = \theta_0x_0 + \theta_1x_1 + \theta_2x_2 + \cdots + \theta_nx_n\\
}}$
</p>

<p>
Parameters
: \(\theta_0,\theta_1,\cdots,\theta_n\rightarrow\theta\,\text{[n+1 dimensional vector]}\)
</p>

<p>
Cost Function
: {{$
\begin{align}
J(\theta_0,\theta_1,\cdots,\theta_n)&amp;\rightarrow J(\theta)\\&amp;= \frac{1}{2m}\sum_{i=1}<sup><small>m(h_\theta(x</small></sup>{(i)}) - y<sup><small>{(i)})</small></sup>2
\end{align}
}}$
</p>

<p>
Gradient descent
: {{$
\begin{align}
&amp;\text{Repeat }\{\\
&amp;\theta_j := \theta_j - \alpha\frac{\partial}{\partial\theta_j}J(\theta_0,\theta_1,\cdots,\theta_n)\\&amp;\}
\end{align}
}}$
</p>

<p>
Some simplifications
</p>
\[
\begin{align}
J(\theta_0,\theta_1,\cdots,\theta_n) &amp;\rightarrow J(\theta)\\
\frac{\partial}{\partial\theta_j}J(\theta)
 &amp;\rightarrow \sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_j^{(i)}
\end{align}
\]

<p>
So, for \(n\geq1\), the gradient descent could be written as
</p>
\[
\begin{align}
&amp;\text{Repeat}\ \{\\
&amp;\theta_j := \theta_j - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_j^{(i)}\\
&amp;\}\ \text{(simultaneously update}\ \theta_j\  \text{for}\ j = 0,\cdots,n\text{)}\\
\end{align}
\]

<p>
Go with the convention that \(x_0^{(i)} = 1\).
</p>

\[
\theta_0 := \theta_0 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_0^{(i)}\\
\theta_1 := \theta_1 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_1^{(i)}\\
\theta_2 := \theta_2 - \alpha\frac{1}{m}\sum_{i=1}^{m}(h_\theta(x^{(i)})- y^{(i)})x_2^{(i)}\\
\vdots
\]

<h2 id="toc_4.3">Gradient Descent in Practice I - Feature Scaling (9 min)</h2>
<p>
Try to normalise the feature values, i.e. get them into the same range of values. This can be visualised using the contour plot
</p>

<p>
Scaling
: If the values are in <em>different ranges</em>, then the contour plot is more like a set of very <em>oblong ellipses</em>
: If there are in the <em>same range</em>, then the contour plot is more like a set on <em>concentric circles</em> and gradient descent will have an easier time homing in on the minimum vale.
Get them in the same range by <em>scaling</em> the values, such that the feature values are in the range \(0 \leq x_i \leq 1\). If that is not exactly the case, it doesn't matter. Same order of magnitude is OK.
Aim for ranges like:
: {{$-3 \leq x_i \leq 3\\
-\frac{1}{3} \leq x_i \leq \frac{1}{3}}}$
</p>
 
<p>
Mean Normalisation
: An alternative to the scaling approach above
: Replace \(x_i\) with \(x_i = \mu_i\) to give feature values a mean of approximately zero.
: No need to do this for \(x_0 = 1\), e.g. {{$
\begin{align}
&amp;x_1 = \frac{size - 1000}{2000}\\
&amp;x_2 = \frac{\#bedrooms-2}{5}\\
&amp;-0.5 \leq x_1 \leq 0.5, -0.5 \leq x_2 \leq 0.5
\end{align}
}}$
For each feature value \(x_1^{(i)}\), perform the transform
</p>
\[
\begin{align}
&amp;&amp;x_1^{(i)} := \frac{x_1^{(i)} - \mu_1}{s_1}\\
&amp;\text{where}&amp;\\
&amp;&amp;\mu_1 \text{ is the mean of }x_1\\
&amp;&amp;s_1 \text{ is the range of }x_1
\end{align}
\]

<h2 id="toc_4.4">Gradient Descent in Practice II - Learning Rate (9 min)</h2>
<p>
Practical rules for determining the <em>learning rate</em>, \(\alpha\).
</p>

<p>
To check that gradient descent is working properly, plot \(J(\theta)\) against number of iterations as gradient descent runs. Should give a descending plot. \(J(\theta)\) should decrease after every iteration.
</p>

<p>
if \(J(\theta)\) increases with number of iterations, that's usually a suggestion that \(\alpha\) is <em>too large</em>.
</p>
<blockquote>
If \(\alpha\) is <em>too large</em> then gradient can <em>overshoot</em>, for example if \(J(\theta)\) is parabolic.
</blockquote>

<p>
If \(J(\theta)\) bounces, it can also suggest that \(\alpha\) is too large.
</p>
<blockquote>
If \(\alpha\) is <em>too small</em>, then gradient descent can be <em>too slow</em>.
</blockquote>

<p>
When choosing \(\alpha\), try
\( \cdots, 0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1, 3, \cdots \)
</p>

<p>
Go with the value that seems to cause \(J(\theta)\) to reduce quickly and with every iteration.
</p>

<p>
<i class="icon-comment"></i> There is a mathematical proof proving that gradient descent <em>will decrease with every iteration</em> provided that \(\alpha\) is chosen correctly.
</p>

<h2 id="toc_4.5">Features and Polynomial Regression (8 min)</h2>

<ul>
<li>
Choice of features

<li>
Polynomial regression

</ul>

<p>
<em>Choice of Features</em>
You can create new features from the existing ones. Existing features could be combined.
</p>

<p>
For example, if the sample data has width and depth of the property, rather than using both those features, instead combine them as area.
</p>

<p>
<em>Polynomial Regression</em>
</p>

<p>
Could choose hypothesis to be second or third order:
</p>

\[
\begin{align}
&amp;\theta_0 + \theta_1x + \theta_2x^2\\
&amp;\theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3
\end{align}
\]

<p>
This form of hypothesis could be used with the the machinery of multi-variate linear regression, like this:
</p>

\[
\begin{align}
h_\theta(x) &amp;= \theta_0 + \theta_1x + \theta_2x^2 + \theta_3x^3\\
&amp;=\theta_0 + \theta_1(size) + \theta_2(size)^2 + \theta_3(size)^3\\
x_1 &amp;= (size)\\
x_2 &amp;= (size)^2\\
x_3 &amp;= (size)^3\\
\end{align}
\]

<p>
<i class="icon-attention"></i><em>Feature scaling</em> is very important to get \(x_1, x_2, x_3\) in the same range.
</p>

<p>
<em>Other Forms of Hypothesis</em>
Instead of a higher order term, consider using something else which might give a better fit, e.g. instead of the top hypothesis, use the bottom one
</p>
\[
\begin{align}
h_\theta(x) &amp;= \theta_0 + \theta_1x + \theta_2x^2\\
\rightarrow h_\theta(x) &amp;= \theta_0 + \theta_1x + \theta_2\sqrt{(size)}
\end{align}
\]

<p>
There is an algorithm which can be used to choose which form of hypothesis would best suit the data.
</p>

<h2 id="toc_4.6">Normal Equation (16 min)</h2>
<p>
Normal equation allows for solving for \(J(\theta)\) analytically.
There are advantages and disadvantages.
</p>

<p>
Simplified case where cost function is quadratic:
</p>
\[
J(\theta) = a\theta^2 + b\theta + c
\]

<p>
To find minimum of a quadratic, take the derivative and set it to zero and solve. Same idea can be used by setting the partial derivatives of the cost funtion for each \(\theta_0,\theta_1,\cdots,\theta_n\) to zero and then solving, i.e.
</p>

\[
\begin{align}
&amp;\frac{\partial}{\partial\theta_j}J(\theta)=\cdots=0\ \text{(for every } j \text{)}\\
&amp;\text{Solve for } \theta_0,\theta_1,\cdots,\theta_n
\end{align}
\]

<p>
In the example, there are four feaures and \(m=4\)
</p>

<ul>
<li>
add a feature \(x_0\) with values 1.

<li>
put all features into a vector, \(X\)

<li>
put all outcomes into a vector, \(y\)

</ul>

\[
X = \begin{bmatrix}
1 &amp;2104 &amp;5 &amp;1 &amp;45\\
1 &amp;1416 &amp;3 &amp;2 &amp;40\\
1 &amp;1534 &amp;3 &amp;2 &amp;30\\
1 &amp;852 &amp;2 &amp;1 &amp;36
\end{bmatrix}
y = \begin{bmatrix}
460\\
232\\
315\\
178
\end{bmatrix}
\]

\[
\theta = (X^TX)^{-1}X^Ty
\]

<p>
<em>Design Matrix</em>
Features look like
</p>
\[
x^{(i)} = \begin{bmatrix}
x_0^{(i)}\\
x_1^{(i)}\\
x_2^{(i)}\\
\vdots\\
x_n^{(i)}\\
\end{bmatrix}
\]
<p>
To construct the <em>design matrix</em>, take the transpose of each \(x^{(i)}\) as each elements of \(X\).
</p>

\[
X = \begin{bmatrix}
(x^{(1)})^T\\
(x^{(2)})^T\\
\vdots\\
(x^{(m)})^T
\end{bmatrix}
\]

<p>
The just compute for \(\theta\) using
</p>
\[
\theta = (X^TX)^{-1}X^Ty
\]

<p>
use <code>pinv()</code> in <em>Octave</em> to calculate the inverse.
</p>

<p>
Calculating a matrix inverse can be expensive, typically \(O(n^3)\). Use the normal equation unless the number of features is greater than \(10000\).
</p>

<p>
Normal equation doesn't work for some of the more complicate machine learning approaches.
</p>
<h2 id="toc_4.7">Normal Equation Noninvertibility (Optional) (6 min)</h2>
<p>
Octave has <code>pinv</code> (<em>pseudo inverse</em>) and <code>inv</code>.
</p>

<p>
If \(X^TX\) is non-invertible, the the normal equation is not going to work.
</p>

<p>
Things that can make \(X^TX\) non-invertible:
</p>

<ul>
<li>
Redundant features

</ul>
<p>
if two features are linearly related, then \(X^TX\) will be non-invertible
</p>
<ul>
<li>
Too many features, \(m \leq n\)

</ul>
<p>
Remove some features to make this work or use <em>regularization</em>.
</p>

<p>
If \(X^TX\) is singular or non-invertible get rid of features where possible or use regularization.
</p>

<h1 id="toc_5">Octave Tutorial (Week 2)</h1>
<h2 id="toc_5.1">Basic Operations (14 min)</h2>
<h2 id="toc_5.2">Moving Data Around (16 min)</h2>
<h2 id="toc_5.3">Computing on Data (13 min)</h2>
<h2 id="toc_5.4">Plotting Data (10 min)</h2>
<h2 id="toc_5.5">Control Statements: for, while, if statements (13 min)</h2>
<h2 id="toc_5.6">Vectorization (14 min)</h2>
<h2 id="toc_5.7">Working on and Submitting Programming Exercises (4 min)</h2>
<h1 id="toc_6">Logistic Regression (Week 3)</h1>
<h2 id="toc_6.1">Classification (8 min)</h2>
<h2 id="toc_6.2">Hypothesis Representation (7 min)</h2>
<h2 id="toc_6.3">Decision Boundary (15 min)</h2>
<h2 id="toc_6.4">Cost Function (11 min)</h2>
<h2 id="toc_6.5">Simplified Cost Function and Gradient Descent (10 min)</h2>
<h2 id="toc_6.6">Advanced Optimization (14 min)</h2>
<h2 id="toc_6.7">Multiclass Classification: One-vs-all (6 min)</h2>
<h1 id="toc_7">Regularization (Week 3)</h1>
<h2 id="toc_7.1">The Problem of Overfitting (10 min)</h2>
<h2 id="toc_7.2">Cost Function (10 min)</h2>
<h2 id="toc_7.3">Regularized Linear Regression (11 min)</h2>
<h2 id="toc_7.4">Regularized Logistic Regression (9 min)</h2>
<h1 id="toc_8">Neural Networks: Representation (Week 4)</h1>
<h2 id="toc_8.1">Non-linear Hypotheses (10 min)</h2>
<h2 id="toc_8.2">Neurons and the Brain (8 min)</h2>
<h2 id="toc_8.3">Model Representation I (12 min)</h2>
<h2 id="toc_8.4">Model Representation II (12 min)</h2>
<h2 id="toc_8.5">Examples and Intuitions I (7 min)</h2>
<h2 id="toc_8.6">Examples and Intuitions II (10 min)</h2>
<h2 id="toc_8.7">Multiclass Classification (4 min)</h2>
<h1 id="toc_9">Neural Networks: Learning (Week 5)</h1>
<h2 id="toc_9.1">Cost Function (7 min)</h2>
<h2 id="toc_9.2">Backpropagation Algorithm (12 min)</h2>
<h2 id="toc_9.3">Backpropagation Intuition (13 min)</h2>
<h2 id="toc_9.4">Implementation Note: Unrolling Parameters (8 min)</h2>
<h2 id="toc_9.5">Gradient Checking (12 min)</h2>
<h2 id="toc_9.6">Random Initialization (7 min)</h2>
<h2 id="toc_9.7">Putting It Together (14 min)</h2>
<h2 id="toc_9.8">Autonomous Driving (7 min)</h2>
<h1 id="toc_10">Advice for Applying Machine Learning (Week 6)</h1>
<h2 id="toc_10.1">Deciding What to Try Next (6 min)</h2>
<h2 id="toc_10.2">Evaluating a Hypothesis (8 min)</h2>
<h2 id="toc_10.3">Model Selection and Train/Validation/Test Sets (12 min)</h2>
<h2 id="toc_10.4">Diagnosing Bias vs# Variance (8 min)</h2>
<h2 id="toc_10.5">Regularization and Bias/Variance (11 min)</h2>
<h2 id="toc_10.6">Learning Curves (12 min)</h2>
<h2 id="toc_10.7">Deciding What to Do Next Revisited (7 min)</h2>
<h1 id="toc_11">Machine Learning System Design (Week 6)</h1>
<h2 id="toc_11.1">Prioritizing What to Work On (10 min)</h2>
<h2 id="toc_11.2">Error Analysis (13 min)</h2>
<h2 id="toc_11.3">Error Metrics for Skewed Classes (12 min)</h2>
<h2 id="toc_11.4">Trading Off Precision and Recall (14 min)</h2>
<h2 id="toc_11.5">Data For Machine Learning (11 min)</h2>
<h1 id="toc_12">Support Vector Machines (Week 7)</h1>
<h2 id="toc_12.1">Optimization Objective (15 min)</h2>
<h2 id="toc_12.2">Large Margin Intuition (11 min)</h2>
<h2 id="toc_12.3">Mathematics Behind Large Margin Classification (Optional) (20 min)</h2>
<h2 id="toc_12.4">Kernels I (16 min)</h2>
<h2 id="toc_12.5">Kernels II (16 min)</h2>
<h2 id="toc_12.6">Using An SVM (21 min)</h2>
<h1 id="toc_13">Clustering (Week 8)</h1>
<h2 id="toc_13.1">Unsupervised Learning: Introduction (3 min)</h2>
<h2 id="toc_13.2">K-Means Algorithm (13 min)</h2>
<h2 id="toc_13.3">Optimization Objective (7 min)</h2>
<h2 id="toc_13.4">Random Initialization (8 min)</h2>
<h2 id="toc_13.5">Choosing the Number of Clusters (8 min)</h2>
<h1 id="toc_14">Dimensionality Reduction (Week 8)</h1>
<h2 id="toc_14.1">Motivation I: Data Compression (10 min)</h2>
<h2 id="toc_14.2">Motivation II: Visualization (6 min)</h2>
<h2 id="toc_14.3">Principal Component Analysis Problem Formulation (9 min)</h2>
<h2 id="toc_14.4">Principal Component Analysis Algorithm (15 min)</h2>
<h2 id="toc_14.5">Choosing the Number of Principal Components (11 min)</h2>
<h2 id="toc_14.6">Reconstruction from Compressed Representation (4 min)</h2>
<h2 id="toc_14.7">Advice for Applying PCA (13 min)</h2>
<h1 id="toc_15">Anomaly Detection (Week 9)</h1>
<h2 id="toc_15.1">Problem Motivation (8 min)</h2>
<h2 id="toc_15.2">Gaussian Distribution (10 min)</h2>
<h2 id="toc_15.3">Algorithm (12 min)</h2>
<h2 id="toc_15.4">Developing and Evaluating an Anomaly Detection System (13 min)</h2>
<h2 id="toc_15.5">Anomaly Detection vs# Supervised Learning (8 min)</h2>
<h2 id="toc_15.6">Choosing What Features to Use (12 min)</h2>
<h2 id="toc_15.7">Multivariate Gaussian Distribution (Optional) (14 min)</h2>
<h2 id="toc_15.8">Anomaly Detection using the Multivariate Gaussian Distribution (Optional) (14 min)</h2>
<h1 id="toc_16">Recommender Systems (Week 9)</h1>
<h2 id="toc_16.1">Problem Formulation (8 min)</h2>
<h2 id="toc_16.2">Content Based Recommendations (15 min)</h2>
<h2 id="toc_16.3">Collaborative Filtering (10 min)</h2>
<h2 id="toc_16.4">Collaborative Filtering Algorithm (9 min)</h2>
<h2 id="toc_16.5">Vectorization: Low Rank Matrix Factorization (8 min)</h2>
<h2 id="toc_16.6">Implementational Detail: Mean Normalization (9 min)</h2>
<h1 id="toc_17">Large Scale Machine Learning (Week 10)</h1>
<h2 id="toc_17.1">Learning With Large Datasets (6 min)</h2>
<h2 id="toc_17.2">Stochastic Gradient Descent (13 min)</h2>
<h2 id="toc_17.3">Mini-Batch Gradient Descent (6 min)</h2>
<h2 id="toc_17.4">Stochastic Gradient Descent Convergence (12 min)</h2>
<h2 id="toc_17.5">Online Learning (13 min)</h2>
<h2 id="toc_17.6">Map Reduce and Data Parallelism (14 min)</h2>
<h1 id="toc_18">Application Example: Photo OCR</h1>
<h2 id="toc_18.1">Problem Description and Pipeline (7 min)</h2>
<h2 id="toc_18.2">Sliding Windows (15 min)</h2>
<h2 id="toc_18.3">Getting Lots of Data and Artificial Data (16 min)</h2>
<h2 id="toc_18.4">Ceiling Analysis: What Part of the Pipeline to Work on Next (14 min)</h2>
<h1 id="toc_19">Conclusion</h1>
<h2 id="toc_19.1">Summary and Thank You (5 min)</h2>

    </div>
</body>
</html>
